{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6h-xYzlR4zD",
        "outputId": "6c76d535-d939-4de3-8679-bd1d4237f3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 16:34:51--  https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241209T163451Z&X-Amz-Expires=300&X-Amz-Signature=af1ca356e7151dc7bb9e5741e7efad7dc1c13a14e7b22eb3b32ea1512d052e7f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-12-09 16:34:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241209T163451Z&X-Amz-Expires=300&X-Amz-Signature=af1ca356e7151dc7bb9e5741e7efad7dc1c13a14e7b22eb3b32ea1512d052e7f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 160610502 (153M) [application/octet-stream]\n",
            "Saving to: ‘model_2024_hairstyle.keras’\n",
            "\n",
            "model_2024_hairstyl 100%[===================>] 153.17M   204MB/s    in 0.8s    \n",
            "\n",
            "2024-12-09 16:34:52 (204 MB/s) - ‘model_2024_hairstyle.keras’ saved [160610502/160610502]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "try:\n",
        "    # Use custom loading method with error handling\n",
        "    model = tf.keras.models.load_model('model_2024_hairstyle.keras', compile=False)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Possible causes:\")\n",
        "    print(\"1. Incorrect file path\")\n",
        "    print(\"2. Corrupted model file\")\n",
        "    print(\"3. Incompatible TensorFlow version\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "fzZKcGV-SFqz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKCIDqt4SPEw",
        "outputId": "cbc84052-920b-41b2-9589-87c94041a719"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "new_name = 'clothing-model-v4.tflite'\n",
        "new_name = 'hairstyle-model-2024.tflite'\n",
        "with tf.io.gfile.GFile(new_name, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjazTRL8SS_z",
        "outputId": "0d557525-a595-4e68-a63a-600f6bc65018"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmphi398yds'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135642603590352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642603600912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601730320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601733312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601721696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602117376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BKHry-qSjPr",
        "outputId": "ecc60a88-838f-479d-d725-0698625f2299"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 235268\n",
            "-rw-r--r-- 1 root root  80296576 Dec  9 16:36 hairstyle-model-2024.tflite\n",
            "-rw-r--r-- 1 root root 160610502 Dec  2 14:28 model_2024_hairstyle.keras\n",
            "drwxr-xr-x 1 root root      4096 Dec  5 14:24 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1 image size (hairstyle-model-2024.tflite) : 80296576"
      ],
      "metadata": {
        "id": "lWJ9Wi95kv4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path='hairstyle-model-2024.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Details:\")\n",
        "for i, input_tensor in enumerate(input_details):\n",
        "    print(f\"Input {i}:\")\n",
        "    print(f\"  Shape: {input_tensor['shape']}\")\n",
        "    print(f\"  Data Type: {input_tensor['dtype']}\")\n",
        "\n",
        "print(\"\\nOutput Details:\")\n",
        "for i, output_tensor in enumerate(output_details):\n",
        "    print(f\"Output {i}:\")\n",
        "    print(f\"  Shape: {output_tensor['shape']}\")\n",
        "    print(f\"  Data Type: {output_tensor['dtype']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9vvaLuLS04U",
        "outputId": "569b1819-90a4-4ec4-e621-4109435e3290"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Details:\n",
            "Input 0:\n",
            "  Shape: [  1 200 200   3]\n",
            "  Data Type: <class 'numpy.float32'>\n",
            "\n",
            "Output Details:\n",
            "Output 0:\n",
            "  Shape: [1 1]\n",
            "  Data Type: <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmJ-OlVqbBgD",
        "outputId": "c9d5a6a0-4083-4441-ea3d-843632a4572a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'serving_default_input_layer:0', 'index': 0, 'shape': array([  1, 200, 200,   3], dtype=int32), 'shape_signature': array([ -1, 200, 200,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9HwHcJKbWWc",
        "outputId": "b2adaa49-7093-4dea-e792-d98524617c22"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'StatefulPartitionedCall_1:0', 'index': 13, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_index = input_details[0]['index']\n",
        "print(f\"Input Index: {input_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7U-9ddCbmsF",
        "outputId": "fa9dd1f8-d2b7-4c16-fce6-91a88cd54529"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Index: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2 What's the output index for this model?"
      ],
      "metadata": {
        "id": "_Q-ERL4jlKyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_index = output_details[0]['index']\n",
        "print(f\"Output Index: {output_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC-JmdcRThMx",
        "outputId": "77603568-b531-4496-a2a4-32dea39aeb74"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Index: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from urllib import request\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def download_image(url):\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    stream = BytesIO(buffer)\n",
        "    img = Image.open(stream)\n",
        "    return img\n",
        "\n",
        "\n",
        "def prepare_image(img, target_size):\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "    img = img.resize(target_size, Image.NEAREST)\n",
        "    return img"
      ],
      "metadata": {
        "id": "332ZThKnUFNU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZXFjacUUGkG",
        "outputId": "3c860aaf-90ca-4d5a-b5db-d5ceb97b704a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'\n",
        "img_d = download_image(img_url)\n"
      ],
      "metadata": {
        "id": "buVErWKzULTW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size = (200, 200)\n",
        "img = prepare_image(img_d, target_size=target_size)"
      ],
      "metadata": {
        "id": "kYgarzENUTA6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array(img, dtype=np.float32) /255.0 # rescal\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miTbKuHmUmHq",
        "outputId": "620c58c7-2cac-4ab0-fa8b-97d41d3b87ec"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GekhIdhUsA9",
        "outputId": "00ef5d7e-45d5-43b2-8cf1-37160f6d8967"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.23921569, 0.40784314, 0.08627451],\n",
              "        [0.25490198, 0.43137255, 0.11372549],\n",
              "        [0.24705882, 0.43137255, 0.1254902 ],\n",
              "        ...,\n",
              "        [0.23921569, 0.34117648, 0.        ],\n",
              "        [0.23921569, 0.34901962, 0.01960784],\n",
              "        [0.20784314, 0.3137255 , 0.00392157]],\n",
              "\n",
              "       [[0.24313726, 0.4117647 , 0.10196079],\n",
              "        [0.2509804 , 0.41960785, 0.10980392],\n",
              "        [0.25490198, 0.41960785, 0.12156863],\n",
              "        ...,\n",
              "        [0.2509804 , 0.34117648, 0.        ],\n",
              "        [0.24313726, 0.33333334, 0.01176471],\n",
              "        [0.21568628, 0.32156864, 0.01960784]],\n",
              "\n",
              "       [[0.26666668, 0.4392157 , 0.13725491],\n",
              "        [0.2627451 , 0.42745098, 0.12941177],\n",
              "        [0.27450982, 0.42352942, 0.12941177],\n",
              "        ...,\n",
              "        [0.2509804 , 0.34901962, 0.03137255],\n",
              "        [0.23137255, 0.32156864, 0.01568628],\n",
              "        [0.20392157, 0.29803923, 0.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.10196079, 0.2       , 0.04313726],\n",
              "        [0.10196079, 0.2       , 0.04313726],\n",
              "        [0.13725491, 0.23921569, 0.05490196],\n",
              "        ...,\n",
              "        [0.88235295, 0.91764706, 0.9137255 ],\n",
              "        [0.8627451 , 0.8980392 , 0.89411765],\n",
              "        [0.89411765, 0.92941177, 0.9254902 ]],\n",
              "\n",
              "       [[0.10196079, 0.1882353 , 0.03921569],\n",
              "        [0.10588235, 0.20392157, 0.03921569],\n",
              "        [0.10980392, 0.21176471, 0.02745098],\n",
              "        ...,\n",
              "        [0.87058824, 0.90588236, 0.9019608 ],\n",
              "        [0.8509804 , 0.8980392 , 0.8901961 ],\n",
              "        [0.8745098 , 0.92156863, 0.9137255 ]],\n",
              "\n",
              "       [[0.10980392, 0.1882353 , 0.04313726],\n",
              "        [0.09019608, 0.1882353 , 0.03137255],\n",
              "        [0.10196079, 0.2       , 0.04313726],\n",
              "        ...,\n",
              "        [0.8784314 , 0.9137255 , 0.9098039 ],\n",
              "        [0.88235295, 0.92156863, 0.91764706],\n",
              "        [0.87058824, 0.91764706, 0.9098039 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3 After the pre-processing, what's the value in the first pixel, the R channel?"
      ],
      "metadata": {
        "id": "v_b-E_CElV_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_channel_value = x[0,0,0]\n",
        "print(r_channel_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TobLHspcUwh5",
        "outputId": "fe8dfacc-f757-425d-ec94-8b6b58400130"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23921569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,0,0], x[0,0,1], x[0,0,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWuFbS-VWeYL",
        "outputId": "bfa056ae-c512-4457-846c-8004c5de2c94"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2392157, 0.40784317, 0.08627451)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4 Now let's apply this model to this image. What's the output of the model?"
      ],
      "metadata": {
        "id": "u-C2CCHLlhoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([x])"
      ],
      "metadata": {
        "id": "cQbZoRozX-vq"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.set_tensor(input_index, X)\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get predictions\n",
        "predictions = interpreter.get_tensor(output_index)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfe5iyjlZOrZ",
        "outputId": "7dd81fa3-c58c-4b7b-9d36-cd36af717e09"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8937741]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq0Cb2FjdG41",
        "outputId": "06f7951e-09e9-45ff-9cad-e4e73bcf49f4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    }
  ]
}